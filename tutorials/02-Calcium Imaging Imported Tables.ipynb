{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with automated computations: Imported tables\n",
    "# Application to Calcium Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back! The practical example of this session is calcium imaging! \n",
    "\n",
    "![pipeline](../images/pipeline-calcium-imaging.svg)\n",
    "\n",
    "During this session you will learn:\n",
    "\n",
    "* To import neuron imaging data from data files into an `Imported` table\n",
    "* To automatically trigger data importing and computations for all the missing entries with `Populate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, let's import `DataJoint` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to perform some computations, let's go ahead and import `NumPy` and `Matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcium imaging dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `data` folder in this `DataJoint-Tutorials`, you can find a small dataset of three different cases of calcium imaging scans: `example_scan_02.tif`, `example_scan_03.tif`and `example_scan_01.tif`.\n",
    "\n",
    "As you might know, calcium imaging scans (raw data) are stored as *.tif* files. \n",
    "\n",
    "*NOTE: For this tutorial there is no need to deeper explore this small dataset. Nevertheless, if you are curious about visualizing these example scans, we recommend you to open the TIFF with [ImageJ](https://imagej.nih.gov/ij/download.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps of the pipeline design: Schema, Mouse & Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataJoint pipeline commonly starts with a `schema` and the following classes for each table: `Mouse` and `Session`. Let's quickly create this pipeline's first steps as we learned it in the previous session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema(\"tutorial\")\n",
    "\n",
    "\n",
    "@schema\n",
    "class Mouse(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    # Experimental animals\n",
    "    mouse_id             : int                          # Unique animal ID\n",
    "    ---\n",
    "    dob=null             : date                         # date of birth\n",
    "    sex=\"unknown\"        : enum('M','F','unknown')      # sex\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@schema\n",
    "class Session(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    # Experiment session\n",
    "    -> Mouse\n",
    "    session_date               : date                         # date\n",
    "    ---\n",
    "    experiment_setup           : int                          # experiment setup ID\n",
    "    experimenter               : varchar(100)                 # experimenter name\n",
    "    data_path=''               : varchar(255)                 # relative path\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "mouse_data = [\n",
    "    {\"dob\": \"2017-03-01\", \"mouse_id\": 0, \"sex\": \"M\"},\n",
    "    {\"dob\": \"2016-11-19\", \"mouse_id\": 1, \"sex\": \"M\"},\n",
    "    {\"dob\": \"2016-11-20\", \"mouse_id\": 2, \"sex\": \"unknown\"},\n",
    "    {\"dob\": \"2016-12-25\", \"mouse_id\": 5, \"sex\": \"F\"},\n",
    "    {\"dob\": \"2017-01-01\", \"mouse_id\": 10, \"sex\": \"F\"},\n",
    "    {\"dob\": \"2017-01-03\", \"mouse_id\": 11, \"sex\": \"F\"},\n",
    "    {\"dob\": \"2017-05-12\", \"mouse_id\": 100, \"sex\": \"F\"},\n",
    "]\n",
    "\n",
    "session_data = [\n",
    "    {\n",
    "        \"experiment_setup\": 0,\n",
    "        \"experimenter\": \"Edgar Y. Walker\",\n",
    "        \"mouse_id\": 0,\n",
    "        \"session_date\": \"2017-05-15\",\n",
    "        \"data_path\": \"../data/\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_setup\": 0,\n",
    "        \"experimenter\": \"Edgar Y. Walker\",\n",
    "        \"mouse_id\": 0,\n",
    "        \"session_date\": \"2017-05-19\",\n",
    "        \"data_path\": \"../data/\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_setup\": 1,\n",
    "        \"experimenter\": \"Fabian Sinz\",\n",
    "        \"mouse_id\": 5,\n",
    "        \"session_date\": \"2017-01-05\",\n",
    "        \"data_path\": \"../data/\",\n",
    "    },\n",
    "    {\n",
    "        \"experiment_setup\": 100,\n",
    "        \"experimenter\": \"Jacob Reimer\",\n",
    "        \"mouse_id\": 100,\n",
    "        \"session_date\": \"2017-05-25\",\n",
    "        \"data_path\": \"../data/\",\n",
    "    },\n",
    "]\n",
    "\n",
    "Mouse.insert(mouse_data, skip_duplicates=True)\n",
    "Session.insert(session_data, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the tables `Mouse` and `Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Scan table and its primary key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a table named `Scan` that describes a scanning in an experimental session of Calcium Imaging. This table will store the scans' metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Scan(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Session\n",
    "    scan_idx    : int           # scan index\n",
    "    ---\n",
    "    depth       : float         # depth of this scan\n",
    "    wavelength  : float         # wavelength used\n",
    "    laser_power : float         # power of the laser used\n",
    "    fps         : float         # frames per second\n",
    "    file_name    : varchar(128) # name of the tif file\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `Scan` is dependent on the table `Session`, inheriting its primary key attributes. In addition, `Scan` has an additional primary key attribute `scan_idx`. \n",
    "\n",
    "One session might contain multiple scans - This is another example of **one-to-many** relationship. \n",
    "\n",
    "Take a look at the `dj.Diagram` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thin solid line connecting [`Mouse`-`Session`] and [`Session`-`Scan`] indicates **one-to-many relationship**.  \n",
    "\n",
    "The underline `____` indicates **additional primary key attribute(s)** apart from the ones inherited from its parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we manually `insert` the metadata of the datasets and their file names in the table `Scan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan.insert(\n",
    "    [\n",
    "        {\n",
    "            \"mouse_id\": 0,\n",
    "            \"session_date\": \"2017-05-15\",\n",
    "            \"scan_idx\": 1,\n",
    "            \"depth\": 150,\n",
    "            \"wavelength\": 920,\n",
    "            \"laser_power\": 26,\n",
    "            \"fps\": 15,\n",
    "            \"file_name\": \"example_scan_01.tif\",\n",
    "        },\n",
    "        {\n",
    "            \"mouse_id\": 0,\n",
    "            \"session_date\": \"2017-05-15\",\n",
    "            \"scan_idx\": 2,\n",
    "            \"depth\": 200,\n",
    "            \"wavelength\": 920,\n",
    "            \"laser_power\": 24,\n",
    "            \"fps\": 15,\n",
    "            \"file_name\": \"example_scan_02.tif\",\n",
    "        },\n",
    "        {\n",
    "            \"mouse_id\": 0,\n",
    "            \"session_date\": \"2017-05-15\",\n",
    "            \"scan_idx\": 3,\n",
    "            \"depth\": 200,\n",
    "            \"wavelength\": 920,\n",
    "            \"laser_power\": 24,\n",
    "            \"fps\": 15,\n",
    "            \"file_name\": \"example_scan_03.tif\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the average frame\n",
    "\n",
    "Let's first load and look at the number of frames of the calcium imaging TIF files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "\n",
    "im = io.imread(\"../data/example_scan_01.tif\")\n",
    "print(\"Number of frames = \", im.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particularly, this example contains 100 frames. \n",
    "\n",
    "Let's calculate the average of the images over the frames and plot the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE!\n",
    "av_frame = np.mean(im, axis=0)\n",
    "plt.imshow(av_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TIP: compute the `average frame` of the `im` image using the mean function from NumPy (np.mean) with axis = 0. Then, plot the result with `imshow`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the table for the average fluorescence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a table `AverageFrame` to compute and save the average fluorescence across the frames. \n",
    "\n",
    "For each scan, we have one average frame. Therefore, the table shares the exact same primary key as the table `Scan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AverageFrame(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Scan\n",
    "    ---\n",
    "    average_frame   : longblob     # average fluorescence across frames\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the state of our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `AverageFrame` and `Scan` share the exact same primary key attributes, so `Scan` and `AverageFrame` have a **one-to-one** relationship, which is indicated with a thick solid line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined `average_frame` as a `longblob`, which allow us to store a NumPy array. This NumPy array will be imported and computed from the file corresponding to each scan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our `AverageFrame` class inherits from `dj.Imported` instead of `dj.Manual` like others. This is because **this table's content will depend on data imported from an external file**. The `Manual` vs `Imported` are said to specify the **tier of the table**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataJoint table tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataJoint, the tier of the table indicates **the nature of the data and the data source for the table**. So far we have encountered two table tiers: `Manual` and `Imported`, and we will encounter the two other major tiers in this session. \n",
    "\n",
    "DataJoint tables in `Manual` tier, or simply **Manual tables** indicate that its contents are **manually** entered by either experimenters or a recording system, and its content **do not depend on external data files or other tables**. This is the most basic table type you will encounter, especially as the tables at the beginning of the pipeline. In the diagram, `Manual` tables are depicted by green rectangles.\n",
    "\n",
    "On the other hand, **Imported tables** are understood to pull data (or *import* data) from external data files, and come equipped with functionalities to perform this importing process automatically, as we will see shortly! In the Diagram, `Imported` tables are depicted by blue ellipses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data into the `Imported` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than filling out the content of the table manually using `insert1` or `insert` methods, we are going to make use of the `make` and `populate` logic that comes with `Imported` tables. These two methods automatically figure it out what needs to be imported, and perform the import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `make` and `populate` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Imported` table comes with a special method called `populate`. Let's call it for `AverageFrame`:\n",
    "\n",
    "*Note that the following code line is intended to generate a code error.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `populate` call complained that a method called `make` is not implemented. Let me show you a simple `make` method that will help elucidate what this is all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class AverageFrame(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Scan\n",
    "    ---\n",
    "    average_frame   : longblob     # average fluorescence across frames\n",
    "    \"\"\"\n",
    "\n",
    "    def make(\n",
    "        self, key\n",
    "    ):  # key is the primary key of one of the entries in the table `Scan`\n",
    "        print(\"key is\", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call `populate` again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE! - call `populate` on the table AverageFrame\n",
    "AverageFrame.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call `populate` on an `Imported` table, this triggers DataJoint to look up all tables that the `Imported` table depends on.\n",
    "\n",
    "For **every unique combination of entries in the depended or \"parent\" tables**, DataJoint calls `make` function, passing in the primary key of the parent(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `AverageFrame` depends on `Scan`, `AverageFrame`'s `make` method was called for each entry of `Scan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `make` only receives the *primary key attributes* of `Scan` (`mouse_id`, `session_date`, `scan_idx`) but not the other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing `make`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a better understanding of `make`, let's implement `make` to perform the importing of data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "@schema\n",
    "class AverageFrame(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Scan\n",
    "    ---\n",
    "    average_frame   : longblob     # average fluorescence across frames\n",
    "    \"\"\"\n",
    "\n",
    "    def make(\n",
    "        self, key\n",
    "    ):  # key is the primary key of one of the entries in the table `Scan`\n",
    "        # fetch data directory from table Session\n",
    "        data_path = (Session & key).fetch1(\"data_path\")\n",
    "\n",
    "        # fetch data file name from table Scan\n",
    "        file_name = (Scan & key).fetch1(\"file_name\")\n",
    "\n",
    "        # load the file\n",
    "        im = io.imread(os.path.join(data_path, file_name))\n",
    "        # compute the average image across the frames\n",
    "        avg_image = np.mean(im, axis=0)\n",
    "\n",
    "        # Now prepare the entry as a dictionary with all fields defined in the table.\n",
    "        key[\"average_frame\"] = avg_image  # inherit the primary key from the table Scan\n",
    "\n",
    "        # insert entry with the method `insert1()`\n",
    "        self.insert1(key)\n",
    "\n",
    "        print(\"\\tPopulated Scan {mouse_id} - {session_date} - {scan_idx}\".format(**key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we added the missing attribute information `average_frame` into the `key` dictionary, and finally **inserted the entry** into `self` (in this case, `self` corresponds to the `AverageFrame` table). The `make` method's job is to create and insert a new entry. This new entry corresponds to the `key` into this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's go ahead and call `populate` to actually populate the `AverageFrame` table with the new content, i.e. filling the table with the data loaded and computed from data files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the table now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we call `AverageFrame.populate` again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right - nothing! This makes sense, because we have computed `AverageFrame` for all entries in `Scan` and nothing is left to be computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what happens if we insert a new entry into `Scan`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan.insert1(\n",
    "    {\n",
    "        \"mouse_id\": 100,\n",
    "        \"session_date\": \"2017-05-25\",\n",
    "        \"scan_idx\": 1,\n",
    "        \"depth\": 150,\n",
    "        \"wavelength\": 920,\n",
    "        \"laser_power\": 25,\n",
    "        \"fps\": 15,\n",
    "        \"file_name\": \"example_scan_03.tif\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the `Scan` entries without their corresponding `AverageFrame` entries using the **negative restriction operator** `-`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all the `Scan` entries *without* a corresponding entry in `AverageFrame`\n",
    "Scan - AverageFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`populate` found the uncomputed entry and processed it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of loading from the raw *.tif* file, we are able to fetch the average fluorescence image from this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict(mouse_id=0, session_date=\"2017-05-15\", scan_idx=1)\n",
    "avg_image = (AverageFrame & key).fetch1(\"average_frame\")\n",
    "plt.imshow(avg_image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully:\n",
    "- Extended your pipeline with a new table to represent the processed data (`AverageFrame` as `Imported` table)\n",
    "- Learned and implemented the `make()` and `populate()` calls to load the external data to your tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our pipeline contains the core elements with the data populated, ready for further downstream analysis.\n",
    "\n",
    "In the next session `03-Calcium Imaging Computed Tables`:\n",
    "- We will introduce the concept of `Computed` table and `Lookup` table\n",
    "- We will also set up an automated computation routine, essential to develop advanced data analyses in your experiments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
